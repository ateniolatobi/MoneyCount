{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "narianet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM27crH1TuJf",
        "colab_type": "text"
      },
      "source": [
        "#**JUPYTER NOTEBOOK FOR TRAINING THE NAIRA CLASSIFIER USED IN MONEYCOUNT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAGnNbZFXf21",
        "colab_type": "text"
      },
      "source": [
        "**Author** \n",
        ": Oluwatobi Victor Ateniola\n",
        "\n",
        "**Objective** : An implementation of a classifier to recognize images of the various denominations of the Naira banknote and also correctly classify the denominations. I built the classifier by modifying a pre-trained mobilenet neural network, I used the mobilenet architecture because of its relatively small size and accuracy. I modified the mobilenet architecure by changing the final sequential layer to classify the banknotes correctly. I made use of pytorch to create and train the model and then I converted the gradients of the trained model to the pytorch mobile format in order to easily integrate in a mobile application.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C-KJz69g-0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43VIG5wg8wFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dirr = \"nairanet/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBuDAY4rlks1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "## TODO: Specify data loaders\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=45),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "    ])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "train_data = datasets.ImageFolder(dirr + \"naira_dataset/train\" , transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(dirr + \"naira_dataset/test\" , transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data , batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data , batch_size=32, shuffle=False)\n",
        "\n",
        "class_names = train_data.classes\n",
        "loaders_transfer = {}\n",
        "\n",
        "loaders_transfer[\"train\"] = trainloader\n",
        "loaders_transfer[\"valid\"] = testloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FLAHtURvSf9",
        "colab_type": "code",
        "outputId": "3237e979-f75d-45b3-8941-228e3dd6f0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(loaders_transfer[\"train\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmBhB-dDqJbi",
        "colab_type": "code",
        "outputId": "364108da-41b8-4fe2-ea99-29d84f8eb12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['05', '10', '100', '1000', '20', '200', '50', '500']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPdXIbG9mVXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaLNKFFtnzjb",
        "colab_type": "code",
        "outputId": "cfa0e704-5023-4a97-e40b-0f9d76b79543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-evfaEOim-WI",
        "colab_type": "code",
        "outputId": "6bb82c7b-1e55-48eb-b77c-e9d61388ce38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "## TODO: Specify model architecture \n",
        "nairanet = mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "for param in nairanet.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "nairanet.classifier = nn.Sequential(\n",
        "                                nn.Dropout(0.4),\n",
        "                                nn.Linear(1280, 512)\n",
        "                                ,nn.ReLU(), \n",
        "                                nn.Dropout(0.3),\n",
        "                                nn.Linear(512, 8)\n",
        "                                )\n",
        "\n",
        "if use_cuda:\n",
        "    nairanet = nairanet.cuda()\n",
        "  \n",
        "# nairanet\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 94.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cvopJthpA4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#Specifying the loss function and the optimizer\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(nairanet.classifier.parameters(), lr=0.04)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-KL9WA2Tsuy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ7MFF1NpZy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for training the model\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            optimizer.zero_grad()\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            output = model.forward(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            loss = None\n",
        "            with torch.no_grad():\n",
        "              output = model.forward(data)\n",
        "              loss = criterion(output, target)\n",
        "            valid_loss += loss.item()\n",
        "        # print training/validation statistics \n",
        "        train_loss = train_loss / len(loaders[\"train\"])\n",
        "        valid_loss = valid_loss / len(loaders[\"valid\"])\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "            # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjXB7d12peyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training the model\n",
        "nairanet = train(50, loaders_transfer, nairanet, optimizer_transfer, criterion_transfer, use_cuda, dirr + 'model/nairanet.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "nairanet.load_state_dict(torch.load(dirr + 'model/nairanet.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPt63yw_rWcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXX8W9N4BB7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for testing the model accuracy\n",
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "# test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrXY8mK9BKVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing the model accuracy\n",
        "test(loaders_transfer, nairanet , criterion_transfer, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcnftCNaqm6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##The block of code moves the code to cpu and then converts to pytorch's mobile format\n",
        "nairanet.to(\"cpu\")\n",
        "nairanet.eval()\n",
        "example = torch.rand(1, 3, 224, 224)\n",
        "traced_script_module = torch.jit.trace(nairanet, example)\n",
        "traced_script_module.save(dirr + 'model/nairanetmobile.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}